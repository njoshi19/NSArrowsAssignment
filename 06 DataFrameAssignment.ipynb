{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chapter 06 - DataFrame Assignment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"C:/Users/njoshi3/Documents/Data Science/NSArrows/\")\n",
    "iris_data = pd.read_csv(\"iris.csv\")\n",
    "print(iris_data)\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Create the following dataframe:\n",
    "#'group': ['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'], 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]}\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "groupounces = [['a',4],['a',3],['a',12],['b',6],['b',7.5],['b',8],['c',3],['c',5],['c',6]]\n",
    "groupouncesdf = pd.DataFrame(groupounces,columns=[\"groups\",\"ounces\"])\n",
    "print(type(groupouncesdf))\n",
    "print(groupouncesdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Another Method\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "groupounces = {\"group\":['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],\n",
    "               \"ounces\":[4, 3, 12, 6, 7.5, 8, 3, 5, 6]}\n",
    "groupouncesdf = pd.DataFrame(groupounces)\n",
    "print(type(groupouncesdf))\n",
    "print(groupouncesdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Sort the data frame in ascending order according to ounces column\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "groupounces = {\"group\":['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],\n",
    "               \"ounces\":[4, 3, 12, 6, 7.5, 8, 3, 5, 6]}\n",
    "groupouncesdf = pd.DataFrame(groupounces)\n",
    "groupouncesdf = groupouncesdf.sort_values(\"ounces\")\n",
    "print(type(groupouncesdf))\n",
    "print(groupouncesdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Multiply each value in the ounces column with 5.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "groupounces = {\"group\":['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],\n",
    "               \"ounces\":[4, 3, 12, 6, 7.5, 8, 3, 5, 6]}\n",
    "groupouncesdf = pd.DataFrame(groupounces)\n",
    "groupouncesdf[\"ounces\"] = groupouncesdf[\"ounces\"]*5\n",
    "groupouncesdf = groupouncesdf.sort_values(\"ounces\")\n",
    "print(type(groupouncesdf))\n",
    "print(groupouncesdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Write a program to calculate the mean, median and total sum of the values in the ounces column.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "groupounces = {\"group\":['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],\n",
    "               \"ounces\":[4, 3, 12, 6, 7.5, 8, 3, 5, 6]}\n",
    "groupouncesdf = pd.DataFrame(groupounces)\n",
    "groupouncesdf[\"ounces\"] = groupouncesdf[\"ounces\"]*5\n",
    "#\n",
    "#Calculating MEAN\n",
    "#\n",
    "dfmean = groupouncesdf[\"ounces\"].mean()\n",
    "print(dfmean)\n",
    "print(type(dfmean))\n",
    "#\n",
    "#Calculating MEDIAN\n",
    "#\n",
    "dfmedian = groupouncesdf[\"ounces\"].median()\n",
    "print(dfmedian)\n",
    "print(type(dfmedian))\n",
    "#\n",
    "#Calculating SUM\n",
    "#\n",
    "dfsum = groupouncesdf[\"ounces\"].sum()\n",
    "print(dfsum)\n",
    "print(type(dfsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 4 columns):\n",
      "Cust_ID    7 non-null object\n",
      "Age        6 non-null float64\n",
      "Gender     6 non-null object\n",
      "City       7 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 304.0+ bytes\n",
      "Customer Info :\n",
      " None\n",
      "Customer Data Type :\n",
      " Cust_ID     object\n",
      "Age        float64\n",
      "Gender      object\n",
      "City        object\n",
      "dtype: object\n",
      "Customer Data Null Check :\n",
      "    Cust_ID    Age  Gender   City\n",
      "0    False  False   False  False\n",
      "1    False  False   False  False\n",
      "2    False  False   False  False\n",
      "3    False  False   False  False\n",
      "4    False  False   False  False\n",
      "5    False  False   False  False\n",
      "6    False   True    True  False\n",
      "Customer Data Null SUM :\n",
      " Cust_ID    0\n",
      "Age        1\n",
      "Gender     1\n",
      "City       0\n",
      "dtype: int64\n",
      "--------------------\n",
      "\n",
      "Customer Data Null Column Wise CUST_ID : 0 False\n",
      "Customer Data Null Column Wise AGE     : 1 True\n",
      "Customer Data Null Column Wise Gender  : 0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "Name: Gender, dtype: bool True\n",
      "Customer Data Null Column Wise City    : 0 False\n",
      "  Cust_ID   Age  Gender     City\n",
      "0  Cust_1  35.0    Male   Mumbai\n",
      "1  Cust_2  24.0  Female  Chennai\n",
      "2  Cust_3  20.0  Female    Delhi\n",
      "3  Cust_4  45.0    Male  Chennai\n",
      "4  Cust_5  37.0    Male   Mumbai\n",
      "5  Cust_6  40.0  Female   Mumbai\n",
      "6  Cust_x   NaN     NaN     Pune\n"
     ]
    }
   ],
   "source": [
    "#Use Adult_information dataset to answer the following,\n",
    "#5. Read the Adult_information dataset and perform the following:\n",
    "#a. Check the information of the dataset\n",
    "#b. Check for the NULL values in the dataset\n",
    "#c. Check for the type values that each column contains in the dataset.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"C:/Users/njoshi3/Documents/Data Science/NSArrows/\")\n",
    "customer_data = pd.read_csv(\"Customer_data.csv\")\n",
    "print(\"Customer Info :\\n\",customer_data.info())\n",
    "print(\"Customer Data Type :\\n\",customer_data.dtypes)\n",
    "print(\"Customer Data Null Check :\\n\",customer_data.isnull())\n",
    "print(\"Customer Data Null SUM :\\n\",customer_data.isnull().sum())\n",
    "print(\"--------------------\\n\")\n",
    "print(\"Customer Data Null Column Wise CUST_ID :\",customer_data[\"Cust_ID\"].isnull().sum(),customer_data[\"Cust_ID\"].isnull().sum()>0)\n",
    "print(\"Customer Data Null Column Wise AGE     :\",customer_data[\"Age\"].isnull().sum(),customer_data[\"Age\"].isnull().sum()>0)\n",
    "print(\"Customer Data Null Column Wise Gender  :\",customer_data[\"Gender\"].isnull(),customer_data[\"Gender\"].isnull().sum()>0)\n",
    "print(\"Customer Data Null Column Wise City    :\",customer_data[\"City\"].isnull().sum(),customer_data[\"City\"].isnull().sum()>0)\n",
    "print(customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cust_ID   Age              Gender     City\n",
      "0  Cust_1  35.0                Male   Mumbai\n",
      "1  Cust_2  24.0              Female  Chennai\n",
      "2  Cust_3  20.0              Female    Delhi\n",
      "3  Cust_4  45.0                Male  Chennai\n",
      "4  Cust_5  37.0                Male   Mumbai\n",
      "5  Cust_6  40.0              Female   Mumbai\n",
      "6  Cust_x  40.0  GenderNotAvailable     Pune\n"
     ]
    }
   ],
   "source": [
    "#6. Replace the NULL values in the dataset.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"C:/Users/njoshi3/Documents/Data Science/NSArrows/\")\n",
    "customer_data = pd.read_csv(\"Customer_data.csv\")\n",
    "customer_data[\"Gender\"].fillna(\"GenderNotAvailable\",inplace=True)\n",
    "customer_data[\"Age\"].fillna(method=\"ffill\",inplace=True)\n",
    "print(customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Create a cross-table of education with target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      patientid  dayofmonth  age gender   bmi  bloodpressure diabetic  \\\n",
      "818         819           3   18   male  43.7            101       No   \n",
      "152         153           7   18   male  27.6             94      Yes   \n",
      "41           42          10   18   male  27.8             93       No   \n",
      "517         518          10   18   male  36.0             93       No   \n",
      "1185       1186          11   18   male  29.7            103       No   \n",
      "326         327          13   18   male  30.8             97      Yes   \n",
      "462         463          13   18   male  29.8             97       No   \n",
      "580         581          14   18   male  32.0             81      Yes   \n",
      "632         633          14   18   male  32.3             98      Yes   \n",
      "1331       1332          15   18   male  41.1            104       No   \n",
      "22           23          18   18   male  35.5            100      Yes   \n",
      "890         891          21   18   male  29.6             81      Yes   \n",
      "564         565          23   18   male  26.6             95       No   \n",
      "244         245          24   18   male  25.5             99      Yes   \n",
      "723         724          28   18   male  30.8             94       No   \n",
      "259         260          30   18   male  30.9             92       No   \n",
      "502         503           2   19   male  22.7             82       No   \n",
      "85           86           3   19   male  27.9             94      Yes   \n",
      "90           91           3   19   male  32.0            100      Yes   \n",
      "730         731           4   19   male  32.3             93      Yes   \n",
      "\n",
      "      children smoker     region  weightlossinGrams  \n",
      "818          1     No  southwest           11576.13  \n",
      "152          0     No  northwest            2523.17  \n",
      "41           0     No  northwest            1635.73  \n",
      "517          2     No  southeast            7160.33  \n",
      "1185         2     No  northeast           32108.66  \n",
      "326          0     No  southwest            4646.76  \n",
      "462          2     No  southeast            6406.41  \n",
      "580          2     No  northwest            8116.27  \n",
      "632          1     No  northwest            8765.25  \n",
      "1331         1    Yes  southeast           48970.25  \n",
      "22           0     No  southeast            1532.47  \n",
      "890          0     No  northeast           12731.00  \n",
      "564          1     No  southeast            7742.11  \n",
      "244          0     No  northeast            3645.09  \n",
      "723          3     No  northeast           10141.14  \n",
      "259          2     No  northwest            3877.30  \n",
      "502          3     No  southeast            6985.51  \n",
      "85           0     No  northeast            1967.02  \n",
      "90           0     No  southeast            1981.58  \n",
      "730          3     No  northwest           10269.46  \n"
     ]
    }
   ],
   "source": [
    "#8. Sort the data in ascending order according to the ‘age’ and ‘hours.per.week’.\n",
    "#8. Sort the data in ascending order according to the ‘age’ and ‘dayofmonth’.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"C:/Users/njoshi3/Documents/Data Science/NSArrows/\")\n",
    "weightlossdata = pd.read_csv(\"WeightLoss.csv\")\n",
    "weightlossdata = weightlossdata.sort_values([\"age\",\"dayofmonth\"])\n",
    "print(weightlossdata.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           weightlossinGrams                                             \n",
      "                         max          mean     median      min        sum\n",
      "age gender                                                               \n",
      "18  male            48970.25  10723.629375   7451.220  1532.47  171578.07\n",
      "19  male            47462.89  13785.379655  10269.460  1146.80  399776.01\n",
      "20  male            46151.12  16147.278846   8862.905  1149.40  419829.25\n",
      "21  male            40273.65  11826.746111   6793.125  1628.47  212881.43\n",
      "22  male            46889.26  21664.031250  19865.850  1826.84  519936.75\n",
      "23  male            47055.53  12455.105357   9286.310  1149.40  348742.95\n",
      "24  male            15170.07   8709.474375   8565.540  1131.51  139351.59\n",
      "25  female          48885.14  12953.233000   6781.675  2899.49  259064.66\n",
      "    male            42760.50  13518.558333  10191.685  1704.57  162222.70\n",
      "26  female          46255.11  10322.036538   8379.435  1759.34  268372.95\n",
      "    male            49577.66  17979.301905   8703.460  2221.56  377565.34\n",
      "27  female          47305.31  14615.587500   9877.875  1744.47  350774.10\n",
      "    male            41676.08  15199.709444  10442.810  1135.94  273594.77\n",
      "28  female          20167.34   9448.233889   9203.685  1633.04  170068.21\n",
      "    male            43921.18  15831.107222   8026.440  1815.88  284959.93\n",
      "29  female          33471.97  10840.535625   8369.315  1634.57  173448.57\n",
      "    male            46718.16  15862.601667   8790.530  1141.45  380702.44\n",
      "30  female          63770.43  20334.770526  18838.700  2166.73  386360.64\n",
      "    male            60021.40  11593.236538   8551.160  1137.01  301424.15\n",
      "31  female          36397.58   9837.980500   7903.100  3578.00  196759.61\n",
      "    male            41097.16  11592.653333   7056.315  1682.60  208667.76\n",
      "32  female          42983.46  13675.129444   6770.765  1727.79  246152.33\n",
      "    male            38415.47  13719.072308   7907.780  1252.41  356695.88\n",
      "33  female          47896.79  12084.976471   8233.100  2217.60  205444.60\n",
      "    male            21259.38  10515.168333  11420.775  2104.11  189273.03\n",
      "34  female          36149.48  10770.606316   7639.420  2730.11  204641.52\n",
      "    male            38344.57  10585.620000   9474.595  1526.31  211712.40\n",
      "35  female          45008.96  13128.991875   8234.165  1622.19  210063.87\n",
      "    male            41034.22  11202.369500   7765.840  1261.44  224047.39\n",
      "36  female          43943.88  14691.856316  11085.590  1615.77  279145.27\n",
      "...                      ...           ...        ...      ...        ...\n",
      "41  female          18955.22   8589.910000   8279.070  2150.47  137438.56\n",
      "    male            47269.85  13997.275000   4933.115  1261.86  111978.20\n",
      "42  female          40932.43  10950.998095  10043.250  1877.93  229970.96\n",
      "    male            45710.21  16227.058125   9335.385  1534.30  259632.93\n",
      "43  female          46113.51  12618.630435   9249.500  1631.67  290228.50\n",
      "    male            52590.83  15444.580000  11272.330  1906.36  417003.66\n",
      "44  female          55135.40  14335.750000  10115.010  2026.97  215036.25\n",
      "    male            51194.56  13023.363500  10613.145  1639.56  260467.27\n",
      "45  female          44400.41  17104.930476  14394.400  2842.76  359203.54\n",
      "    male            48675.52  13339.148421  11013.710  1515.34  253443.82\n",
      "46  female          34838.87  11571.334375   7931.905  3238.44  185141.35\n",
      "    male            41999.52  14527.518214   7622.440  2438.06  406770.51\n",
      "47  female          46200.99  13875.222667  10713.640  1631.82  208128.34\n",
      "    male            46130.53  15003.788261  11326.710  1137.47  345087.13\n",
      "48  female          37079.37   9627.737000   6441.485  2020.18  192554.74\n",
      "    male            37829.72   8872.948500   6706.490  1391.53  177458.97\n",
      "49  female          47928.03  13095.035000   7686.520  1633.96  235710.63\n",
      "    male            48673.56  10360.826500   3280.680  1263.25  207216.53\n",
      "50  female          39983.43  12957.134118  11729.680  1607.51  220271.28\n",
      "    male            44501.40  16174.878000   9620.330  1720.35  242623.17\n",
      "51  female          41661.60  11409.010000  10381.480  1728.90  193953.17\n",
      "52  female          48824.45  16298.176111  10993.160  1629.83  293367.17\n",
      "53  female          27808.73  11546.692000  10338.930  1880.07  173200.38\n",
      "54  female          40419.02   9840.272353   7727.250  2020.55  167284.63\n",
      "55  female          42969.85  12083.380385   7389.685  2217.47  314167.89\n",
      "56  female          46661.44  13892.810000   9374.580  4718.20  250070.58\n",
      "57  female          45863.21  13109.417619  11073.180  2597.78  275297.77\n",
      "58  female          37270.15  12093.242353   7935.290  1621.88  205585.12\n",
      "59  female          58571.07  13514.357273  11070.605  2117.34  297315.86\n",
      "60  female          44641.20  13180.474762   9625.920  1731.68  276789.97\n",
      "\n",
      "[69 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#9. Create a pivot table for the sum of working hours of the ‘target’ and ‘hours.per.week’.\n",
    "# Here we are doing pivot table for the sum of weightlossingrams of the Age and Gender\n",
    "weightlosspivot = weightlossdata.pivot_table(index=[\"age\",\"gender\"],\n",
    "                                            values=[\"weightlossinGrams\"],\n",
    "                                            aggfunc={'sum','max','median', 'mean', 'min'})\n",
    "print(weightlosspivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  StudentId       StudentName  Marks\n",
      "0        S1  Danniella Fenton    200\n",
      "1        S2      Ryder Storey    201\n",
      "2        S3      Bryce Jensen    190\n",
      "3        S4         Ed Bernal    222\n",
      "4        S5       Kwame Morin    199\n",
      "  StudentId       StudentName  Marks\n",
      "0        S4  Scarlette Fisher    201\n",
      "1        S5  Carla Williamson    200\n",
      "2        S6       Dante Morse    198\n",
      "3        S7    Kaiser William    219\n",
      "4        S8   Madeeha Preston    201\n",
      "  StudentId StudentName_x  Marks_x     StudentName_y  Marks_y\n",
      "0        S4     Ed Bernal      222  Scarlette Fisher      201\n",
      "1        S5   Kwame Morin      199  Carla Williamson      200\n"
     ]
    }
   ],
   "source": [
    "#10. Write a program to inner join the two given data frames.\n",
    "#Create dataframe from the following data:\n",
    "#student_data1:\n",
    "#  student_id name marks\n",
    "#0 S1 Danniella Fenton 200\n",
    "#1 S2 Ryder Storey 210\n",
    "#2 S3 Bryce Jensen 190\n",
    "#3 S4 Ed Bernal 222\n",
    "#4 S5 Kwame Morin 199\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "studentdata1 = {\"StudentId\":[\"S1\",\"S2\",\"S3\",\"S4\",\"S5\"],\n",
    "               \"StudentName\":[\"Danniella Fenton\",\"Ryder Storey\",\"Bryce Jensen\",\"Ed Bernal\",\"Kwame Morin\"],\n",
    "               \"Marks\":[200,201,190,222,199]}\n",
    "studentdatadf1 = pd.DataFrame(studentdata1)\n",
    "print(studentdatadf1)\n",
    "#student_data2:\n",
    "#student_id name marks\n",
    "#0 S4 Scarlette Fisher 201\n",
    "#1 S5 Carla Williamson 200\n",
    "#2 S6 Dante Morse 198\n",
    "#3 S7 Kaiser William 219\n",
    "#4 S8 Madeeha Preston 201\n",
    "studentdata2 = {\"StudentId\":[\"S4\",\"S5\",\"S6\",\"S7\",\"S8\"],\n",
    "               \"StudentName\":[\"Scarlette Fisher\",\"Carla Williamson\",\"Dante Morse\",\"Kaiser William\",\"Madeeha Preston\"],\n",
    "               \"Marks\":[201,200,198,219,201]}\n",
    "studentdatadf2 = pd.DataFrame(studentdata2)\n",
    "print(studentdatadf2)\n",
    "# Inner Join: Inner join is the most common type of join you’ll be working with. \n",
    "# It returns a dataframe with only those rows that have common characteristics. \n",
    "# This is similar to the intersection of two sets.\n",
    "innerjoindf = pd.merge(studentdatadf1,studentdatadf2,on=\"StudentId\",how=\"inner\")\n",
    "print(innerjoindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  StudentId     StudentName_x  Marks_x     StudentName_y  Marks_y\n",
      "0        S1  Danniella Fenton    200.0               NaN      NaN\n",
      "1        S2      Ryder Storey    201.0               NaN      NaN\n",
      "2        S3      Bryce Jensen    190.0               NaN      NaN\n",
      "3        S4         Ed Bernal    222.0  Scarlette Fisher    201.0\n",
      "4        S5       Kwame Morin    199.0  Carla Williamson    200.0\n",
      "5        S6               NaN      NaN       Dante Morse    198.0\n",
      "6        S7               NaN      NaN    Kaiser William    219.0\n",
      "7        S8               NaN      NaN   Madeeha Preston    201.0\n",
      "  StudentId StudentName_x  Marks_x     StudentName_y  Marks_y\n",
      "0        S4     Ed Bernal    222.0  Scarlette Fisher      201\n",
      "1        S5   Kwame Morin    199.0  Carla Williamson      200\n",
      "2        S6           NaN      NaN       Dante Morse      198\n",
      "3        S7           NaN      NaN    Kaiser William      219\n",
      "4        S8           NaN      NaN   Madeeha Preston      201\n",
      "  StudentId     StudentName_x  Marks_x     StudentName_y  Marks_y\n",
      "0        S1  Danniella Fenton      200               NaN      NaN\n",
      "1        S2      Ryder Storey      201               NaN      NaN\n",
      "2        S3      Bryce Jensen      190               NaN      NaN\n",
      "3        S4         Ed Bernal      222  Scarlette Fisher    201.0\n",
      "4        S5       Kwame Morin      199  Carla Williamson    200.0\n"
     ]
    }
   ],
   "source": [
    "#11. Write a program to outer join the two given data frames.\n",
    "#Full Outer Join: A full outer join returns all the rows from the left dataframe, \n",
    "#all the rows from the right dataframe, and matches up rows where possible, with NaNs elsewhere.\n",
    "#But if the dataframe is complete, then we get the same output.\n",
    "#\n",
    "fullouterjoindf = pd.merge(studentdatadf1,studentdatadf2,on=\"StudentId\",how=\"outer\")\n",
    "print(fullouterjoindf)\n",
    "#\n",
    "#12. Write a program to right join the two given data frames.\n",
    "#Right Outer Join: For a right join, all the records from the second dataframe will be displayed.\n",
    "#However, only the records with the keys in the first dataframe that can be found in the second dataframe will be displayed.\n",
    "#\n",
    "rightouterjoindf = pd.merge(studentdatadf1,studentdatadf2,on=\"StudentId\",how=\"right\")\n",
    "print(rightouterjoindf)\n",
    "#\n",
    "#13. Write a program to Left join the two given data frames\n",
    "#Left Outer Join: With a left outer join, all the records from the first dataframe will be displayed, \n",
    "#irrespective of whether the keys in the first dataframe can be found in the second dataframe. \n",
    "#Whereas, for the second dataframe, only the records with the keys in the second dataframe that can be found \n",
    "#in the first dataframe will be displayed.\n",
    "#\n",
    "leftouterjoindf = pd.merge(studentdatadf1,studentdatadf2,on=\"StudentId\",how=\"left\")\n",
    "print(leftouterjoindf)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "x = 'print(55)'\n",
    "eval(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
